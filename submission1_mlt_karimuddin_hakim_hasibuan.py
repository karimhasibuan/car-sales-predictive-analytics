# -*- coding: utf-8 -*-
"""Submission1_MLT_Karimuddin_Hakim_Hasibuan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D327gXelefCo8aQO8C830aaDQATDBVso

**Prediksi Harga Mobil -Submission Machine Learning Terapan**

Oleh: Karimuddin Hakim Hasibuan

# Menyiapkan dataset

Pada tahapan ini dataset akan diimport ke dalam google colab melalui kaggle. Tujuannya untuk menggunakan dataset sebagai data yang akan menjadi model prediksi harga mobil.
"""

# import kredential akun dari kaggle
from google.colab import files
files.upload()

# mengatur akses kredential akun kaggle agar dapat menggunakan API Kaggle untuk mengunduh dataset
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# mengunduh dataset dari kaggle
!kaggle datasets download -d suraj520/car-sales-data

# mengekstrak file zip dataset agar dapat digunakan
import zipfile
zip_ref = zipfile.ZipFile('car-sales-data.zip', 'r')
zip_ref.extractall('')
zip_ref.close()

# menampilkan 5 data teratas dan 5 paling bawah pada dataset

import pandas as pd

dataset = pd.read_csv('car_sales_data.csv')
print('5 Data teratas:')
print(dataset.head())

print('5 data terbawah:')
print(dataset.tail())

"""# Pre-prosesing data

Pada tahapan ini data akan melalui proses Exploratory Data Analysis (EDA). Bertujuan untuk mendapatkan insight data.

1. Mengecek tipe data pada setiap kolom.
"""

dataset.info()

"""2. Menampilkan distribusi data yang digunakan."""

dataset.describe()

"""3. Memeriksa apakah terdapat nilai null pada setiap kolom."""

# Memeriksa nilai null atau missing value pada setiap kolom
missing_values = dataset.isnull().sum()

# Menampilkan jumlah nilai null pada setiap kolom
print("Jumlah nilai null pada setiap kolom:")
print(missing_values)

"""4. Memeriksa apakah terdapat nilai 0 pada kolom 'Car Year' dan 'Sale Price'. Hal ini dilakukan karna tidak mungkin tahun pembuatan dan harga mobil senilai 0."""

# Memeriksa nilai yang sama dengan 0 pada kolom 'Car Year'
car_year_zeros = (dataset['Car Year'] == 0).sum()
print("Jumlah nilai 0 pada kolom 'Car Year':", car_year_zeros)

# Memeriksa nilai yang sama dengan 0 pada kolom 'Sale Price'
sale_price_zeros = (dataset['Sale Price'] == 0).sum()
print("Jumlah nilai 0 pada kolom 'Sale Price':", sale_price_zeros)

"""5. Memeriksa apakah terdapat baris yang memiliki data duplikat."""

# memeriksa baris yang duplikat
dataset.duplicated().sum()

"""6. Mengecek data outlier menggunakan metode IQR (Interquartile Range) dan menghapus data yang outlier pada data numerik yaitu (Car Year, Sale Price, Commission Rate, Commission Earned)."""

import seaborn as sns
import matplotlib.pyplot as plt

# Memilih kolom-kolom numerik
numeric_columns = ['Car Year', 'Sale Price', 'Commission Rate', 'Commission Earned']

# Membuat boxplot untuk setiap kolom numerik
plt.figure(figsize=(6, 4))
for i, column in enumerate(numeric_columns):
    plt.subplot(2, 2, i+1)
    sns.boxplot(data=dataset, y=column)
    plt.title(column)
plt.tight_layout()
plt.show()

# Memilih kolom-kolom numerik
numeric_columns = ['Car Year', 'Sale Price', 'Commission Rate', 'Commission Earned']

# Menghitung batas bawah (lower bound) dan batas atas (upper bound) menggunakan metode IQR
for column in numeric_columns:
    Q1 = dataset[column].quantile(0.25)
    Q3 = dataset[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Menghitung jumlah data yang dianggap sebagai outlier
    num_outliers = len(dataset[(dataset[column] < lower_bound) | (dataset[column] > upper_bound)])

    # Menampilkan hasil
    print("Jumlah outlier pada kolom", column, ":", num_outliers)

"""Berdasarkan hasil diatas, dapat diketahui bahwa kolom Commission Earned memiliki data outliers. Untuk itu, data yang outliers akan dihapus."""

# Menghapus data outlier berdasarkan metode IQR
for column in numeric_columns:
    Q1 = dataset[column].quantile(0.25)
    Q3 = dataset[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Menghapus data outlier
    dataset = dataset[(dataset[column] >= lower_bound) & (dataset[column] <= upper_bound)]

# Menampilkan dataset yang telah dihapus outlier
print(len(dataset))

"""Setelah menghapus data yang outlier, sekarang jumlah datanya adalah 2496568.

7. Menampilkan distribusi data pada setiap kolom. Bertujuan untuk mendapatkan informasi lebih mengenai data.
"""

import matplotlib.pyplot as plt

# Menghitung frekuensi masing-masing tanggal (Date)
date_counts = dataset['Date'].value_counts().reset_index()

# Mengubah nama kolom
date_counts.columns = ['Date', 'Frequency']

# Mengurutkan tanggal secara ascending
date_counts = date_counts.sort_values('Date')

# Membuat line chart
plt.plot(date_counts['Date'], date_counts['Frequency'])
plt.xlabel('Date')
plt.ylabel('Frequency')
plt.title('Frequency of Date')
plt.xticks(rotation=45)
plt.show()

# Mengkonversi kolom 'Date' menjadi tipe data date
dataset['Date'] = pd.to_datetime(dataset['Date'])

# Mendapatkan tahun dari setiap tanggal
dataset['Year'] = dataset['Date'].dt.year

# Menghitung frekuensi masing-masing tahun
year_counts = dataset['Year'].value_counts().reset_index()

# Mengubah nama kolom
year_counts.columns = ['Year', 'Frequency']

# Menampilkan tabel frekuensi berdasarkan tahun
print(year_counts)

"""Berdasarkan hasil diatas, dapat diketahui bahwa tahun penjualan lebih banyak terjadi pada tahun 2022. Selanjutnya, mari kita analisis data Salesperson dan Customer Name."""

# Menghitung frekuensi masing-masing Salesperson
salesperson_counts = dataset['Salesperson'].value_counts()

# Membuat DataFrame dan mengurutkannya berdasarkan frekuensi
salesperson_table = pd.DataFrame({'Salesperson': salesperson_counts.index, 'Frequency': salesperson_counts.values})
salesperson_table = salesperson_table.sort_values(by='Frequency', ascending=False)

# Menampilkan tabel frekuensi yang diurutkan
print(salesperson_table)

"""Berdasarkan hasil diatas, dapat diketahui bahwa top 5 sales adalah Michael Smith, Michael Johnson, David Smith, James Smith, dan Jennifer Smith dengan angka penjualan secara berurutan adalah 1227, 976, 821, 795, dan 752. Total sales sebanyak 518350 sales."""

# Menghitung frekuensi masing-masing Customer Name
customer_counts = dataset['Customer Name'].value_counts()

# Membuat DataFrame dan mengurutkannya berdasarkan frekuensi
customer_table = pd.DataFrame({'Customer Name': customer_counts.index, 'Frequency': customer_counts.values})
customer_table = customer_table.sort_values(by='Frequency', ascending=False)

# Menampilkan tabel frekuensi customer yang diurutkan
print(customer_table)

"""Berdasarkan hasil diatas, dapat diketahui bahwa top 5 customer adalah Michael Smith, Michael Johnson, David Smith, James Smith, dan Jennifer Smith dengan angka penjualan secara berurutan adalah 1163, 889, 795, 788, dan 786. Total customer sebanyak 517935 customer."""

# Mengambil nama unik dari kolom Salesperson
salesperson_names = set(dataset['Salesperson'].unique())

# Mengambil nama unik dari kolom Customer Name
customer_names = set(dataset['Customer Name'].unique())

# Menggabungkan dua set nama
combined_names = salesperson_names.union(customer_names)

# Menghitung jumlah nama yang muncul di kedua kolom
total_names = len(combined_names)

# Menampilkan nama-nama yang ada pada kedua kolom dan jumlahnya
print("Nama-nama yang ada pada kedua kolom Salesperson dan Customer Name:")
for name in combined_names:
    print(name)

print("Jumlah nama yang muncul pada kedua kolom:", total_names)

"""Berdasarkan hasil pemeriksaan diatas, ternyata ditemukan 698362 nama yang merupakan Sales dan Customer. Selanjutnya, kita analisis data Car Make (merk mobil yang dibeli)."""

# Menghitung frekuensi masing-masing Car Make
car_make_counts = dataset['Car Make'].value_counts()

# Mengurutkan frekuensi dari yang paling banyak
car_make_counts = car_make_counts.sort_values(ascending=False)

# Menampilkan tabel frekuensi Car Make yang diurutkan
print(car_make_counts)

"""Berdasarkan hasil diatas, dapat diketahui merk yang paling banyak laku adalah Honda. Sedangkan, merk mobil yang paling sedikit laku adalah Nissan. Selanjutnya, kita analisis model dari merk mobil yang dibeli berdasarkan data pada kolom Car Model."""

# Menghitung frekuensi masing-masing Car Model
car_model_counts = dataset['Car Model'].value_counts()

# Mengurutkan frekuensi dari yang paling banyak
car_model_counts = car_model_counts.sort_values(ascending=False)

# Menampilkan tabel frekuensi Car Model yang diurutkan
print(car_model_counts)

"""Berdasarkan hasil diatas, dapat diketahui model yang paling banyak laku adalah Silverado. Sedangkan, model mobil yang paling sedikit laku adalah Altima. Namun, model Silverado dari merk Chevrolet memiliki angka penjualan model tertinggi, padahal untuk kategori merk, merk Honda merupakan yang tertinggi. Selanjutnya, menganalisis persoalan tersebut."""

# Mengambil data unique Car Make dan Car Model
unique_car_make = dataset['Car Make'].unique()
unique_car_model = dataset['Car Model'].unique()

# Menampilkan data unique Car Make
print("Unique Car Make:")
print(unique_car_make)

# Menampilkan data unique Car Model
print("Unique Car Model:")
print(unique_car_model)

# Menghitung frekuensi Silverado dan Civic
silverado_count = dataset.loc[dataset['Car Model'] == 'Silverado', 'Car Make'].value_counts()
civic_count = dataset.loc[dataset['Car Model'] == 'Civic', 'Car Make'].value_counts()

# Menampilkan frekuensi Silverado dan Civic
print("Frekuensi Silverado:")
print(silverado_count)
print("Frekuensi Civic:")
print(civic_count)

"""Berdasarkan hasil diatas, ternyata untuk model Silverado juga dimiliki oleh setiap merk mobil, begitu juga dengan model Civic. Selanjutnya, menganalisis data pada kolom Car Year untuk mengetahui tahun penjualan mobil."""

# Menghitung frekuensi masing-masing Car Year
car_year_counts = dataset['Car Year'].value_counts()

# Mengurutkan frekuensi dari yang paling banyak
car_year_counts = car_year_counts.sort_values(ascending=False)

# Menampilkan tabel frekuensi Car Year yang diurutkan
print(car_year_counts)

# Membuat line chart
plt.figure(figsize=(10, 6))
plt.bar(car_year_counts.index, car_year_counts.values)
plt.xlabel('Car Year')
plt.ylabel('Frequency')
plt.title('Distribution of Car Year')
plt.xticks(rotation=45)
plt.show()

"""Berdasarkan hasil diatas, dapat diketahui bahwa mobil tahun 2013 merupakan yang paling laku dan tahun 2022 merupakan tahun mobil yang paling sedikit dibandingkan yang lainnya. Selanjutnya, mari kita cari tahu seri mobil yang paling mahal dan paling murah berdasarkan data pada kolom Sale Price."""

# Mendapatkan data dengan harga paling mahal
most_expensive = dataset.nlargest(1, 'Sale Price')
# Mendapatkan data dengan harga paling murah
cheapest = dataset.nsmallest(1, 'Sale Price')

# Menampilkan data dengan harga paling mahal
print("Merk mobil, model mobil, dan tahun mobil dengan harga paling mahal:")
print("Car Make:", most_expensive['Car Make'].values[0])
print("Car Model:", most_expensive['Car Model'].values[0])
print("Car Year:", most_expensive['Car Year'].values[0])
print("Sale Price:", most_expensive['Sale Price'].values[0])

# Menampilkan data dengan harga paling murah
print("Merk mobil, model mobil, dan tahun mobil dengan harga paling murah:")
print("Car Make:", cheapest['Car Make'].values[0])
print("Car Model:", cheapest['Car Model'].values[0])
print("Car Year:", cheapest['Car Year'].values[0])
print("Sale Price:", cheapest['Sale Price'].values[0])

"""Berdasarkan hasil diatas, dapat diketahui merk mobil Nissan, model F-150 tahun 2013 merupakan mobil yang paling mahal. Sedangkan, merk mobil Nissan, model Altima tahun 2012 merupakan mobil yang paling murah. Selanjutnya, akan dilakukan persiapan dataset untuk diproses ke model Regresi Linier, Decision Tree, dan Random Forest."""

print(dataset.columns)

"""Kita akan melakukan drop pada kolom yang tidak relevan untuk diproses ke model seperti 'Date', 'Salesperson', 'Customer Name' dan 'Year'."""

dataset = dataset.drop(['Date', 'Salesperson', 'Customer Name', 'Year'], axis=1)

"""Setelah kolom 'Date', 'Salesperson', 'Customer Name' dan 'Year' di drop, selanjutnya melakukan encoding pada variabel kategorikal yaitu pada kolom 'Car Make' dan  'Car Model'."""

encoded_dataset = pd.get_dummies(dataset, columns=['Car Make', 'Car Model'])
print(encoded_dataset)

"""Dataset yang sudah di encoding kemudian disimpan dalam variabel baru yaitu encoded_dataset. Selanjutnya, kita akan melakukan Feature Scaling pada kolom numerik menggunakan MinMaxScaler(), yang berfungsi untuk melakukan normalisasi dan standarisasi data."""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaled_features = scaler.fit_transform(encoded_dataset[['Car Year', 'Commission Rate', 'Commission Earned']])
encoded_dataset[['Car Year', 'Commission Rate', 'Commission Earned']] = scaled_features

encoded_dataset

"""Selanjutnya, memisahkan kolom fitur dan target. Dalam hal ini, kolom fitur yaitu kolom selain 'Sale Price' dan kolom target adalah 'Sale Price'."""

X = encoded_dataset.drop('Sale Price', axis=1)
y = encoded_dataset['Sale Price']

"""Melakukan pembagian dataset menjadi data latih dan data uji. Data latih akan digunakan untuk melatih model, sedangkan data uji akan digunakan untuk menguji performa model. Data latih dibagi menjadi 80% dan data uji 20% dari total dataset."""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Selanjutnya, melakukan modelling menggunakan algoritma Regresi Linier, Decision Tree dan K-Nearest Neighbors (KNN)."""

#Modelling menggunakan algoritma Linear Regression
from sklearn.linear_model import LinearRegression

linear_regression = LinearRegression()
linear_regression.fit(X_train, y_train)

#Modelling menggunakan algoritma Decision Tree
from sklearn.tree import DecisionTreeRegressor

decision_tree = DecisionTreeRegressor()
decision_tree.fit(X_train, y_train)

#Modelling menggunakan algoritma KNN
from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor()
knn.fit(X_train, y_train)

"""Setelah dilakukan modelling, selanjutnya dilakukan dengan melakukan evaluasi menggunakan matriks MSE dan MAE dari hasil prediksi data pada model. Langkah pertama, adalah melakukan scaling terhadap fitur numerik."""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
numerical_features = ['Car Year', 'Commission Rate', 'Commission Earned']

X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""Selanjutnya, dilakukan evaluasi menggunakan matriks MSE dan MAE pada hasil prediksi."""

from sklearn.metrics import mean_squared_error, mean_absolute_error

# Evaluasi model Regresi Linear
linear_regression_pred = linear_regression.predict(X_test)
linear_regression_mse = mean_squared_error(y_test, linear_regression_pred)
linear_regression_mae = mean_absolute_error(y_test, linear_regression_pred)
print("MSE Regresi Linear:", linear_regression_mse)
print("MAE Regresi Linear:", linear_regression_mae)

# Evaluasi model Decision Tree
decision_tree_pred = decision_tree.predict(X_test)
decision_tree_mse = mean_squared_error(y_test, decision_tree_pred)
decision_tree_mae = mean_absolute_error(y_test, decision_tree_pred)
print("MSE Decision Tree:", decision_tree_mse)
print("MAE Decision Tree:", decision_tree_mae)

# Evaluasi model KNN
knn_pred = knn.predict(X_test)
knn_mse = mean_squared_error(y_test, knn_pred)
knn_mae = mean_absolute_error(y_test, knn_pred)
print("MSE KNN:", knn_mse)
print("MAE KNN:", knn_mae)

"""Berdasarkan hasil diatas, dapat diketahui bahwa Decision Tree maupun KNN memberikan hasil prediksi yang lebih baik dengan nilai MSE dan MAE yang lebih rendah dibandingkan Regresi Linier. Oleh karena itu, untuk dataset ini, model Decision Tree dan KNN lebih disarankan untuk digunakan dalam melakukan prediksi Sale Price."""

prediksi = X_test.iloc[:1].copy()
print("Sale Price Asli:", y_test[:1])

# Prediksi menggunakan Regresi Linear
linear_regression_pred = linear_regression.predict(prediksi).round(1)
print("Prediksi Regresi Linear:", linear_regression_pred)

# Prediksi menggunakan Decision Tree
decision_tree_pred = decision_tree.predict(prediksi).round(1)
print("Prediksi Decision Tree:", decision_tree_pred)

# Prediksi menggunakan KNN
knn_pred = knn.predict(prediksi).round(1)
print("Prediksi KNN:", knn_pred)

"""Berdasarkan hasil pengujian prediksi diatas, memang hasil pada algoritma Decision Tree yang paling mendekati kemudian disusul oleh KNN dan ada algoritma Regresi Linear. Meski begitu, hasil prediksi masih jauh dari nilai asli.

Selanjutnya, kita akan melihat fitur apa yang paling berpengaruh dalam menentukan harga mobil menggunakan algoritma Decision Tree.
"""

importance_scores = decision_tree.feature_importances_
feature_names = X_train.columns

# Mengurutkan skor pentingnya fitur secara menurun
sorted_indices = importance_scores.argsort()[::-1]
sorted_scores = importance_scores[sorted_indices]
sorted_features = feature_names[sorted_indices]

# Menampilkan skor pentingnya fitur
for feature, score in zip(sorted_features, sorted_scores):
    print(f"{feature}: {score}")

"""Hasil yang didapatkan menunjukkan skor pentingnya fitur dalam menentukan Sale Price. Setiap fitur memiliki skor penting yang dinyatakan sebagai angka.

Misalnya, "Commission Earned" memiliki skor penting sebesar 0.7083596164141285, yang berarti fitur tersebut memiliki pengaruh yang paling signifikan dalam menentukan Sale Price. Skor penting ini dapat diinterpretasikan sebagai persentase kontribusi fitur tersebut dalam mempengaruhi Sale Price.

Selanjutnya, "Commission Rate" memiliki skor penting sebesar 0.2916393396038089, yang menunjukkan bahwa fitur ini juga memiliki pengaruh yang cukup signifikan dalam menentukan Sale Price, meskipun tidak sebesar "Commission Earned".

Fitur-fitur lainnya, seperti "Car Year", "Car Make_Nissan", "Car Make_Toyota", dan seterusnya, memiliki skor penting yang sangat kecil, bahkan mendekati nol. Hal ini menunjukkan bahwa fitur-fitur tersebut memiliki pengaruh yang relatif kecil atau kurang signifikan dalam memprediksi Sale Price.

Dalam konteks ini, skor penting yang lebih tinggi menandakan bahwa fitur tersebut memiliki pengaruh yang lebih besar dalam menentukan Sale Price, sedangkan skor penting yang lebih rendah menandakan pengaruh yang lebih kecil.

Dalam beberapa kasus, komisi yang diperoleh dan tingkat komisi yang diterapkan dapat mencerminkan karakteristik penjualan mobil tertentu. Misalnya, mobil dengan harga jual yang lebih tinggi mungkin memiliki komisi yang lebih besar, atau komisi yang diberikan untuk penjualan mobil tertentu mungkin lebih tinggi dibandingkan dengan mobil lainnya. Oleh karena itu, fitur-fitur ini dapat memberikan informasi penting dalam memprediksi Sale Price.
"""